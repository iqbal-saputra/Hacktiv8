{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perkenalan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nama**: Muhammad Iqbal Saputra\n",
    "\n",
    "**Batch**: RMT 032\n",
    "\n",
    "**Objective**: Objektif dari program ini adalah untuk membuat model klasifikasi menggunakan Logistic Regression, SVC, KNN, Decision Tree, Random Forest, dan AdaBoostClassifier untuk memprediksi apakah pengiriman akan tepat waktu atau tidak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dataset](https://www.kaggle.com/datasets/nayanack/shipping/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Library Numerical Data\n",
    "import numpy as np\n",
    "\n",
    "# Library Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries for Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, kendalltau, spearmanr, uniform, randint\n",
    "\n",
    "# Library Clustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_score,silhouette_samples\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Libraries for Modeling ML\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score,KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_absolute_error, roc_auc_score,mean_squared_error, root_mean_squared_error, r2_score, accuracy_score , classification_report , confusion_matrix,precision_score, recall_score, f1_score,ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from feature_engine.outliers import Winsorizer\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# lib pipelines\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Model Saving\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "\n",
    "# To ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Column Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Feature   | Description                                                                                                           |\n",
    "| ----------|-----------------------------------------------------------------------------------------------------------------------|\n",
    "| ID      | ID Number of Customers.|\n",
    "| Warehouse block       | The Company have big Warehouse which is divided in to block such as A,B,C,D,E.|\n",
    "| Mode of shipment       | The Company Ships the products in multiple way such as Ship, Flight and Road.|\n",
    "| Customer care calls      | The number of calls made from enquiry for enquiry of the shipment.\n",
    "| Customer rating      | The company has rated from every customer. 1 is the lowest (Worst), 5 is the highest (Best).\n",
    "| Cost of the product      | Cost of the Product in US Dollars.\n",
    "| Prior purchases     | The Number of Prior Purchase.\n",
    "| Product importance    | The company has categorized the product in the various parameter such as low, medium, high.\n",
    "| Gender    | Male and Female.| \n",
    "| Discount offered       | Discount offered on that specific product.|\n",
    "| Weight in gms   | It is the weight in grams.|\n",
    "| Reached on time      | It is the target variable, where 1 Indicates that the product has NOT reached on time and 0 indicates it has reached on time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new dataset\n",
    "df = pd.read_csv('shipping.csv')\n",
    "# Show first 10 data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show last 10 data\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Dataset\n",
    "new_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset info\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari informasi dataset tersebut kita dapat melihat bahwa:\n",
    "* Terdapat `12` kolom di dalam dataset\n",
    "* Tipe data terdiri dari `8` **integer** dan `4` **object**\n",
    "* Terdapat `10999` entri dalam kumpulan data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column ID\n",
    "new_data=new_data.drop(['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe dataset\n",
    "new_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicated data\n",
    "new_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tidak ada data yang duplikat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan info data\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting between numerical and categorical columns\n",
    "num_columns = ['Customer_care_calls', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms']\n",
    "cat_columns = [col for col in new_data.columns if col not in num_columns]\n",
    "\n",
    "\n",
    "print('Categorical Columns: ', cat_columns)\n",
    "print('Numcerical Columns: ', num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(16, 5))\n",
    "plt.pie(new_data['Reached.on.Time_Y.N'].value_counts(), labels=['Reached on time', 'Not reached on time'], explode=[0, 0.1], autopct='%.0f%%', colors=['#7A288A', '#808080'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisasi data menunjukkan bahwa pengiriman yang `not reached on time` mencapai `60%`, sedangkan yang `reached on time` hanya `40%`. Hal ini mengindikasikan adanya ketidakseimbangan (imbalance) dalam distribusi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the categorical columns\n",
    "cat_columns = new_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a figure with a specified size\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 4))\n",
    "for i, col in enumerate(cat_columns[:4]):\n",
    "    sns.countplot(data=new_data, x=col, hue=new_data['Reached.on.Time_Y.N'], palette='pastel', ax=axs[i])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan**\n",
    "* **warehouse_block**: Pada blok F terdapat banyak pengiriman yang `not reached on time`.\n",
    "* **mode_of_shipment**: Pada metode pengiriman `ship` ditemukan banyak pengiriman yang `not reached on time`.\n",
    "* **product_importance**: Pada tingkat kepentingan produk `low` terdapat banyak pengiriman yang `not reached on time`.\n",
    "* **gender**: Pada kedua jenis kelamin ditemukan banyak pengiriman yang `not reached on time`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the outliers of numerical data\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "cols = num_columns\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "\n",
    "for index in range(1, num_rows*num_cols):\n",
    "    fig.add_subplot(num_rows, num_cols, index)\n",
    "    sns.boxplot(data=new_data, y=cols[index-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kolom `Prior_purhcase` dan `Discount_offered` :\n",
    "- terdapat banyak **outliers** yang harus di handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot kolom pengiriman\n",
    "sns.countplot(data=new_data,x=\"Mode_of_Shipment\")\n",
    "plt.title(\"Type of shipments (Most Used)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pengiriman lebih banyak menggunakan kapal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perbandingan metode pengiriman\n",
    "plt.figure(figsize=(10,6))\n",
    "grouped=df.groupby([\"Mode_of_Shipment\",\"Product_importance\"])[\"Cost_of_the_Product\"].sum().unstack()\n",
    "ax=grouped.plot(kind=\"bar\")\n",
    "ax\n",
    "plt.title(\"Model of shipment vs product_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perbandingan metode pengiriman\n",
    "plt.figure(figsize=(10,6))\n",
    "grouped=df.groupby([\"Mode_of_Shipment\",\"Product_importance\"])[\"Weight_in_gms\"].sum().unstack()\n",
    "ax=grouped.plot(kind=\"bar\")\n",
    "ax\n",
    "plt.title(\"Model of shipment vs Weight_in_gms \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perbandingan metode pengiriman\n",
    "plt.figure(figsize=(10,6))\n",
    "grouped=df.groupby([\"Mode_of_Shipment\",\"Product_importance\"])[\"Discount_offered\"].sum().unstack()\n",
    "ax=grouped.plot(kind=\"bar\")\n",
    "ax\n",
    "plt.title(\"Model of shipment vs Discount_offered \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan**  \n",
    "Untuk diskon kapal ditawarkan lebih banyak dan juga karena harga dan berat produk semakin banyak orang yang memilih kapal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handling Cardinality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset info\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting between numerical and categorical columns\n",
    "num_columns = ['Customer_care_calls', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms']\n",
    "cat_columns = [col for col in new_data.columns if col not in num_columns]\n",
    "\n",
    "\n",
    "print('Categorical Columns: ', cat_columns)\n",
    "print('Numcerical Columns: ', num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan**  \n",
    "membagi kolom menjadi kolom numerik dan kategorikal agar lebih mudah dianalisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making empty list for appending the unique values\n",
    "cat_columns_unique = []\n",
    "# Inspect the Number of Different Labels, for Different Categorical Variables\n",
    "for cat in cat_columns:\n",
    "    cat_columns_unique.append([cat, new_data[cat].nunique()])\n",
    "\n",
    "# Showing dataframe consisting \n",
    "pd.DataFrame(data=cat_columns_unique, columns=['categorical_column', 'unique_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Kolom                   | Unique Value |\n",
    "|-------------------------|--------------|\n",
    "| Warehouse_block         | 5            |\n",
    "| Mode_of_Shipment        | 3            |\n",
    "| Customer_rating         | 5            |\n",
    "| Product_importance      | 3            |\n",
    "| Gender                  | 2            |\n",
    "| Reached.on.Time_Y.N     | 2            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Between X and Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split fitur X dan Y\n",
    "X = new_data.drop('Reached.on.Time_Y.N', axis=1)\n",
    "y = new_data['Reached.on.Time_Y.N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Between Train and Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train dan test menggunakan pareto principle\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y ,test_size=0.2 ,random_state=43)\n",
    "print('Train Size', X_train.shape)\n",
    "print('Test Size', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting numerical dan categorical columns\n",
    "num_columns = ['Customer_care_calls', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms']\n",
    "cat_columns = [col for col in new_data.columns if col not in num_columns]\n",
    "\n",
    "\n",
    "print('Categorical Columns: ', cat_columns)\n",
    "print('Numcerical Columns: ', num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handling Missing Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null in dataset\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null in dataset\n",
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null in dataset\n",
    "y_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null in dataset\n",
    "y_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tidak terdapat missing value dalam data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handling Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making data and columns for normal distribution\n",
    "data_normal = []\n",
    "column_normal = []\n",
    "\n",
    "# Making data and columns for skewed distribution\n",
    "data_skewed = []\n",
    "column_skewed = []\n",
    "\n",
    "# For loop in every numerical column to filer the data distribution into either normal distributed or skewed columns\n",
    "for num in num_columns:\n",
    "    skewness = X_train[num].skew()\n",
    "    \n",
    "    # If the data normally distributed\n",
    "    if skewness <= 0.5 and skewness >= -0.5:            \n",
    "        column_normal.append(num)\n",
    "        data_normal.append([num, skewness])\n",
    "        \n",
    "    # Elif the data has low skewness\n",
    "    elif skewness < -0.5 and skewness > -1: \n",
    "        column_skewed.append(num)\n",
    "        data_skewed.append([num, skewness, 'low'])\n",
    "\n",
    "    # Elif the data has low skewness\n",
    "    elif skewness > 0.5 and skewness < 1:\n",
    "        column_skewed.append(num)\n",
    "        data_skewed.append([num, skewness, 'low'])\n",
    "\n",
    "    # Elif the data has high skewness\n",
    "    elif skewness < -1 or skewness > 1:\n",
    "        column_skewed.append(num)\n",
    "        data_skewed.append([num, skewness, 'high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing normally distributed columns\n",
    "pd.DataFrame(data=data_normal, columns=['normal_distribution', 'skewness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom  `Customer_care_calls`, `Cost_of_the_Product`, dan `Weight_in_gms ` adalah **normal distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing skewed columns\n",
    "pd.DataFrame(data=data_skewed, columns=['skewed_distribution', 'skewness', 'rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom `Prior_purchases`, dan `Discount_offered` adalah **skew distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capping Method for Normal Distribution  \n",
    "winsorizer_normal = Winsorizer(capping_method='gaussian',\n",
    "                            tail='both',\n",
    "                            fold=3,\n",
    "                            variables=column_normal,\n",
    "                            missing_values='ignore')\n",
    "\n",
    "# Fit & Transforming X_train \n",
    "X_train_capped = winsorizer_normal.fit_transform(X_train)\n",
    "\n",
    "# Transforming X_test\n",
    "X_test_capped = winsorizer_normal.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capping kolom yang **terdistribusi normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capping Method for Skewed Distribution  \n",
    "winsorizer_skewed = Winsorizer(capping_method='iqr',\n",
    "                            tail='both',\n",
    "                            fold=1.5,\n",
    "                            variables=column_skewed)\n",
    "\n",
    "# Fit & Transforming X_train \n",
    "X_train_capped = winsorizer_skewed.fit_transform(X_train_capped)\n",
    "\n",
    "# Transforming X_test\n",
    "X_test_capped = winsorizer_skewed.transform(X_test_capped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capping kolom **terdistribusi skew**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Distribution Comparison\n",
    "def outlier_handling_plot_comparison(df_before, df_after, variable):\n",
    "\n",
    "    # Figure Size, and Super Title based on variable\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))                               \n",
    "    fig.suptitle(f'{variable} - Distribution Before and After Outlier Handling')\n",
    "\n",
    "    # Plot Histogram Before\n",
    "    sns.histplot(df_before[variable], bins=30, ax=axes[0, 0], color='orange')\n",
    "    axes[0, 0].set_title('Histogram Before')\n",
    "\n",
    "    # Plot Boxplot Before\n",
    "    sns.boxplot(y=df_before[variable], ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Boxplot Before')\n",
    "\n",
    "    # Plot Histogram After\n",
    "    sns.histplot(df_after[variable], bins=30, ax=axes[0, 1], color='orange')\n",
    "    axes[0, 1].set_title('Histogram After')\n",
    "\n",
    "    # Plot Boxplot After\n",
    "    sns.boxplot(y=df_after[variable], ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Boxplot After')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi untuk menunjukkan perbedaan setiap kolom sebelum dan sesudah penanganan outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping untuk kolom numerik\n",
    "for num in num_columns:\n",
    "    outlier_handling_plot_comparison(X_train, X_train_capped, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before dan after setelah di capping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting Numerical and Categorical Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting between numerical and categorical columns\n",
    "num_columns = ['Customer_care_calls', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms']\n",
    "cat_columns = ['Warehouse_block', 'Mode_of_Shipment', 'Customer_rating', 'Product_importance', 'Gender']\n",
    "\n",
    "print('Categorical Columns: ', cat_columns)\n",
    "print('Numcerical Columns: ', num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the train and test features into categorical and numerical columns\n",
    "X_train_num = X_train_capped[num_columns]\n",
    "X_train_cat = X_train_capped[cat_columns]\n",
    "\n",
    "X_test_num = X_test_capped[num_columns]\n",
    "X_test_cat = X_test_capped[cat_columns]\n",
    "\n",
    "X_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan kolom numerik pada X_train\n",
    "X_train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk uji korelasi antar data kategorikal, kita akan menggunakan uji korelasi **kendall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the correlation between categorical columns and Y Train using Kendall Tau's correlation\n",
    "p_values = []\n",
    "interpretation = []\n",
    "cols = []\n",
    "corr = []\n",
    "selected_cat_cols = []\n",
    "\n",
    "for col in X_train_cat.columns:\n",
    "  corr_coef, p_value = kendalltau(X_train_cat[col], y_train)\n",
    "\n",
    "  p_values.append(p_value)\n",
    "  cols.append(col)\n",
    "  corr.append(corr_coef)\n",
    "\n",
    "  if p_value < 0.05:\n",
    "    interpretation.append('Significant')\n",
    "    selected_cat_cols.append(col)\n",
    "  else :\n",
    "    interpretation.append('Not Significant')\n",
    "\n",
    "pd.DataFrame({'Column Name':cols,\n",
    "              'Correlation Coefficient' : corr,\n",
    "              'P-value':p_values,\n",
    "              'Correlation': interpretation })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom kategorik yang memiliki korelasi significant adalah kolom **Product_impotance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the correlation between numerical columns and Y Train using pearsonr and spearmanr correlation\n",
    "p_values = []\n",
    "interpretation = []\n",
    "cols = []\n",
    "corr = []\n",
    "selected_num_cols = []\n",
    "\n",
    "for col in X_train_num.columns:\n",
    "  if abs(X_train_num[col].skew()) < 0.5:                    \n",
    "    # For Normally Distributed Columns\n",
    "    corr_coef, p_value = pearsonr(X_train_num[col], y_train)\n",
    "\n",
    "    p_values.append(p_value)\n",
    "    cols.append(col)\n",
    "    corr.append(corr_coef)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "      interpretation.append('Significant')\n",
    "      selected_num_cols.append(col)\n",
    "    else :\n",
    "      interpretation.append('Not Significant')\n",
    "  else:                                                     \n",
    "    # For Skewed Columns\n",
    "    corr_coef, p_value = spearmanr(X_train_num[col], y_train)\n",
    "\n",
    "    p_values.append(p_value)\n",
    "    cols.append(col)\n",
    "    corr.append(corr_coef)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "      interpretation.append('Significant')\n",
    "      selected_num_cols.append(col)\n",
    "    else :\n",
    "      interpretation.append('Not Significant')\n",
    "\n",
    "pd.DataFrame({'Column Name':cols,\n",
    "              'Correlation Coefficient' : corr,\n",
    "              'P-value':p_values,\n",
    "              'Correlation': interpretation })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelima kolom tersebut memiliki korelasi yang significant\n",
    "`Customer_care_calls`,`Cost_of_the_Product`,`Prior_purchases`,`Discount_offered`,dan `Weight_in_gms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show selected columns based on the correlation test\n",
    "print(selected_cat_cols)\n",
    "print(selected_num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Numerical and Categorical Columns\n",
    "X_train_cat = X_train_cat[selected_cat_cols]\n",
    "X_train_num = X_train_num[selected_num_cols]\n",
    "\n",
    "X_test_cat = X_test_cat[selected_cat_cols]\n",
    "X_test_num = X_test_num[selected_num_cols]\n",
    "\n",
    "# Show first five data from the updated X_train\n",
    "X_train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan kolom katogerik pada X_train\n",
    "X_train_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memperbarui dan memisahkan `X_train` dan `X_test` untuk hanya menampilkan kolom numerik dan kategorikal yang berkorelasi signifikan dengan kolom target. Setelah pemisahan ini, kita dapat beralih ke `feature scaling` dan `feature encoding`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk `feature scalling`, kita akan menggunakan `MinMax Scaler` untuk menskalakan data ke rentang tertentu. Ini akan membantu menormalkan data dan memastikan bahwa semua fitur memiliki skala yang sama. `MinMax Scaler` berguna ketika fitur memiliki unit atau range yang berbeda, karena dapat mencegah fitur yang memiliki banyak outlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline mengotomatisasi alur kerja machine learning, memungkinkan data untuk diubah dan dikorelasikan ke dalam model secara otomatis. Karena kita ingin melihat model klasifikasi mana yang bekerja paling baik untuk dataset ini, **pipeline dapat menghemat banyak waktu dan usaha**.\n",
    "\n",
    "Ada beberapa `langkah` yang akan kita gunakan dalam semua model pipeline kita, seperti:\n",
    "\n",
    "1. Untuk **`Feature Scaling`** dalam pipeline ini, kita akan menggunakan `MinMax Scaler` untuk menskalakan data ke rentang tertentu, yang dapat membantu menormalkan data dan memastikan semua fitur memiliki skala yang sama. `MinMax Scaler` berguna ketika fitur memiliki unit atau rentang yang berbeda, karena dapat mencegah fitur dengan rentang yang lebih besar mendominasi proses pembelajaran.\n",
    "\n",
    "2. Untuk membuat **`Pipeline dengan Banyak Variabel`**, dalam kasus kita data numerik dan kategorikal, kita akan menggunakan `Column Transformer` karena memungkinkan kita untuk **menggunakan langkah-langkah preprocessing yang berbeda** untuk setiap tipe data.\n",
    "\n",
    "3. Untuk **`Definisi Model`**, kita akan menggunakan model `Random Forest` dan `AdaBoost`, untuk melihat model mana yang paling cocok dengan data.\n",
    "\n",
    "4. Untuk **`Pelatihan Model`**, kita akan melatih setiap model dengan fitur akhir dan target yang seimbang.\n",
    "\n",
    "5. Untuk **`Evaluasi Model`**, kita akan mengukur `recall`, karena kita ingin mengevaluasi **false negative**. False negative dalam konteks ini berarti pengiriman yang sebenarnya terlambat tetapi diprediksi tepat waktu, yang dapat menyebabkan masalah operasional.\n",
    "\n",
    "6. Untuk **`Cross Validation`**, kita menggunakan `K-fold cross validation` karena kita ingin **mengurangi overfitting** dan mendapatkan evaluasi model yang lebih akurat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing pipelines\n",
    "num_pipeline = make_pipeline(MinMaxScaler())\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder()) \n",
    "\n",
    "# Define preprocessing column transformer\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, selected_num_cols),\n",
    "    ('cat', cat_pipeline, selected_cat_cols)\n",
    "])\n",
    "\n",
    "# Define model pipeline\n",
    "model_pipeline = make_pipeline(preprocessing_pipeline, SVC(kernel='rbf', probability=True, class_weight='balanced'))\n",
    "\n",
    "#Model Training\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions for training and test sets\n",
    "y_train_pred = model_pipeline.predict(X_train)\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Generate classification reports for training and test sets\n",
    "print(f'Train Recall Score Before Tuning : \\n', recall_score(y_train, y_train_pred), '\\n')\n",
    "print(f'Test Recall Score Before Tuning: \\n', recall_score(y_test, y_test_pred), '\\n')\n",
    "\n",
    "# Cross Validation\n",
    "recall_train_cross_val = cross_val_score(model_pipeline,\n",
    "                                     X_train,\n",
    "                                     y_train,\n",
    "                                     cv=10,\n",
    "                                     scoring=\"recall\")\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "svm_results_df = pd.DataFrame({\n",
    "    'Metric': ['Train Recall', 'Test Recall', 'CV Recall Mean', 'CV Recall Std'],\n",
    "    'Value': [recall_score(y_train, y_train_pred), recall_score(y_test, y_test_pred), recall_train_cross_val.mean(), recall_train_cross_val.std()]\n",
    "})\n",
    "\n",
    "print(svm_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Evaluasi Model SVM\n",
    "\n",
    "#### Train Recall Score Before Tuning:\n",
    "- **Nilai**: 0.4372492836676218\n",
    "- **Penjelasan**: Nilai recall pada data training menunjukkan bahwa model SVM mampu mengenali 43.72% dari total kasus positif di dalam data training. Ini menunjukkan bahwa model masih memiliki banyak false negatives, di mana kasus positif tidak terdeteksi oleh model.\n",
    "\n",
    "#### Test Recall Score Before Tuning:\n",
    "- **Nilai**: 0.4435240963855422\n",
    "- **Penjelasan**: Nilai recall pada data testing menunjukkan bahwa model SVM mampu mengenali 44.35% dari total kasus positif di dalam data testing. Hasil ini mirip dengan recall pada data training, yang menunjukkan bahwa model memiliki kinerja yang konsisten tetapi tidak optimal dalam mendeteksi kasus positif.\n",
    "\n",
    "#### Tabel Evaluasi Model:\n",
    "| Metric         | Value    |\n",
    "|----------------|----------|\n",
    "| Train Recall   | 0.437249 |\n",
    "| Test Recall    | 0.443524 |\n",
    "| CV Recall Mean | 0.435728 |\n",
    "| CV Recall Std  | 0.020225 |\n",
    "\n",
    "- **Train Recall**: Nilai ini menunjukkan bahwa model dapat mengenali sekitar 43.72% dari total kasus positif pada data training. \n",
    "- **Test Recall**: Nilai ini menunjukkan bahwa model dapat mengenali sekitar 44.35% dari total kasus positif pada data testing. Nilai ini hampir sama dengan train recall, menunjukkan kinerja yang konsisten antara data training dan testing.\n",
    "- **CV Recall Mean**: Nilai rata-rata recall dari 10-fold cross-validation adalah 0.435728. Ini menunjukkan bahwa secara keseluruhan, model mampu mengenali sekitar 43.57% dari total kasus positif pada data validasi silang. \n",
    "- **CV Recall Std**: Standar deviasi recall dari 10-fold cross-validation adalah 0.020225. Nilai ini menunjukkan variasi atau ketidakpastian dari hasil recall pada setiap fold dalam cross-validation. Standar deviasi yang kecil menunjukkan bahwa hasil model cukup konsisten di seluruh fold cross-validation.\n",
    "\n",
    "### Kesimpulan:\n",
    "Model SVM yang digunakan belum optimal dalam mengenali kasus positif, dengan nilai recall yang relatif rendah baik pada data training, testing, maupun cross-validation. Hal ini menunjukkan bahwa banyak kasus positif yang tidak terdeteksi oleh model (false negatives tinggi). Model ini mungkin memerlukan tuning hyperparameter atau mungkin model lain yang lebih cocok dengan data yang ada untuk meningkatkan performa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing pipelines\n",
    "num_pipeline = make_pipeline(MinMaxScaler())\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder()) \n",
    "\n",
    "# Define preprocessing column transformer\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, selected_num_cols),\n",
    "    ('cat', cat_pipeline, selected_cat_cols)\n",
    "])\n",
    "\n",
    "# Define model pipeline\n",
    "model_pipeline = make_pipeline(preprocessing_pipeline, KNeighborsClassifier())\n",
    "\n",
    "#Model Training\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions for training and test sets\n",
    "y_train_pred = model_pipeline.predict(X_train)\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Generate classification reports for training and test sets\n",
    "print(f'Train Recall Score Before Tuning : \\n', recall_score(y_train, y_train_pred), '\\n')\n",
    "print(f'Test Recall Score Before Tuning: \\n', recall_score(y_test, y_test_pred), '\\n')\n",
    "\n",
    "# Cross Validation\n",
    "recall_train_cross_val = cross_val_score(model_pipeline,\n",
    "                                     X_train,\n",
    "                                     y_train,\n",
    "                                     cv=10,\n",
    "                                     scoring=\"recall\")\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "knn_results_df = pd.DataFrame({\n",
    "    'Metric': ['Train Recall', 'Test Recall', 'CV Recall Mean', 'CV Recall Std'],\n",
    "    'Value': [recall_score(y_train, y_train_pred), recall_score(y_test, y_test_pred), recall_train_cross_val.mean(), recall_train_cross_val.std()]\n",
    "})\n",
    "\n",
    "print(knn_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Evaluasi Model KNN\n",
    "\n",
    "#### Train Recall Score Before Tuning:\n",
    "- **Nilai**: 0.7759312320916906\n",
    "- **Penjelasan**: Nilai recall pada data training menunjukkan bahwa model KNN mampu mengenali 77.59% dari total kasus positif di dalam data training. Ini menunjukkan bahwa model cukup baik dalam mendeteksi kasus positif pada data training.\n",
    "\n",
    "#### Test Recall Score Before Tuning:\n",
    "- **Nilai**: 0.677710843373494\n",
    "- **Penjelasan**: Nilai recall pada data testing menunjukkan bahwa model KNN mampu mengenali 67.77% dari total kasus positif di dalam data testing. Hasil ini lebih rendah dibandingkan dengan recall pada data training, menunjukkan bahwa model sedikit overfitting dan mungkin tidak mampu mengenali kasus positif pada data testing sebaik pada data training.\n",
    "\n",
    "#### Tabel Evaluasi Model:\n",
    "| Metric         | Value    |\n",
    "|----------------|----------|\n",
    "| Train Recall   | 0.775931 |\n",
    "| Test Recall    | 0.677711 |\n",
    "| CV Recall Mean | 0.661133 |\n",
    "| CV Recall Std  | 0.019071 |\n",
    "\n",
    "- **Train Recall**: Nilai ini menunjukkan bahwa model dapat mengenali sekitar 77.59% dari total kasus positif pada data training. Model menunjukkan kinerja yang cukup baik dalam mengenali kasus positif pada data training.\n",
    "- **Test Recall**: Nilai ini menunjukkan bahwa model dapat mengenali sekitar 67.77% dari total kasus positif pada data testing. Meskipun lebih rendah dari nilai recall pada data training, nilai ini masih menunjukkan kinerja yang baik dalam mengenali kasus positif pada data testing.\n",
    "- **CV Recall Mean**: Nilai rata-rata recall dari 10-fold cross-validation adalah 0.661133. Ini menunjukkan bahwa secara keseluruhan, model mampu mengenali sekitar 66.11% dari total kasus positif pada data validasi silang. \n",
    "- **CV Recall Std**: Standar deviasi recall dari 10-fold cross-validation adalah 0.019071. Nilai ini menunjukkan variasi atau ketidakpastian dari hasil recall pada setiap fold dalam cross-validation. Standar deviasi yang kecil menunjukkan bahwa hasil model cukup konsisten di seluruh fold cross-validation.\n",
    "\n",
    "### Kesimpulan:\n",
    "Model KNN yang digunakan menunjukkan performa yang cukup baik dalam mengenali kasus positif, dengan nilai recall yang lebih tinggi dibandingkan model SVM sebelumnya. Namun, ada indikasi sedikit overfitting karena recall pada data training lebih tinggi dibandingkan dengan data testing. Meskipun demikian, model ini masih mampu memberikan kinerja yang baik dan konsisten di berbagai fold cross-validation. Untuk meningkatkan performa lebih lanjut, tuning hyperparameter dapat dilakukan atau metode lain dapat dipertimbangkan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing pipelines\n",
    "num_pipeline = make_pipeline(MinMaxScaler())\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder()) \n",
    "\n",
    "# Define preprocessing column transformer\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, selected_num_cols),\n",
    "    ('cat', cat_pipeline, selected_cat_cols)\n",
    "])\n",
    "\n",
    "# Define model pipeline\n",
    "model_pipeline = make_pipeline(preprocessing_pipeline, DecisionTreeClassifier())\n",
    "\n",
    "#Model Training\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions for training and test sets\n",
    "y_train_pred = model_pipeline.predict(X_train)\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Generate classification reports for training and test sets\n",
    "print(f'Train Recall Score Before Tuning : \\n', recall_score(y_train, y_train_pred), '\\n')\n",
    "print(f'Test Recall Score Before Tuning: \\n', recall_score(y_test, y_test_pred), '\\n')\n",
    "\n",
    "# Cross Validation\n",
    "recall_train_cross_val = cross_val_score(model_pipeline,\n",
    "                                     X_train,\n",
    "                                     y_train,\n",
    "                                     cv=10,\n",
    "                                     scoring=\"recall\")\n",
    "\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "dt_results_df = pd.DataFrame({\n",
    "    'Metric': ['Train Recall', 'Test Recall', 'CV Recall Mean', 'CV Recall Std'],\n",
    "    'Value': [recall_score(y_train, y_train_pred), recall_score(y_test, y_test_pred), recall_train_cross_val.mean(), recall_train_cross_val.std()]\n",
    "})\n",
    "\n",
    "print(dt_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Evaluasi Model Decision Tree\n",
    "\n",
    "#### Train Recall Score Before Tuning:\n",
    "- **Nilai**: 1.0\n",
    "- **Penjelasan**: Nilai recall pada data training menunjukkan bahwa model Decision Tree mampu mengenali 100% dari total kasus positif di dalam data training. Ini menunjukkan bahwa model sangat baik dalam mendeteksi semua kasus positif pada data training, tetapi mungkin mengalami overfitting karena performa yang terlalu sempurna.\n",
    "\n",
    "#### Test Recall Score Before Tuning:\n",
    "- **Nilai**: 0.7093373493975904\n",
    "- **Penjelasan**: Nilai recall pada data testing menunjukkan bahwa model Decision Tree mampu mengenali 70.93% dari total kasus positif di dalam data testing. Hasil ini menunjukkan penurunan kinerja dibandingkan dengan data training, yang mungkin mengindikasikan overfitting.\n",
    "\n",
    "#### Tabel Evaluasi Model:\n",
    "| Metric         | Value    |\n",
    "|----------------|----------|\n",
    "| Train Recall   | 1.000000 |\n",
    "| Test Recall    | 0.709337 |\n",
    "| CV Recall Mean | 0.704109 |\n",
    "| CV Recall Std  | 0.011219 |\n",
    "\n",
    "- **Train Recall**: Nilai ini menunjukkan bahwa model dapat mengenali 100% dari total kasus positif pada data training. Model ini menunjukkan tanda-tanda overfitting, di mana model terlalu cocok dengan data training.\n",
    "- **Test Recall**: Nilai ini menunjukkan bahwa model dapat mengenali sekitar 70.93% dari total kasus positif pada data testing. Meskipun lebih rendah dari nilai recall pada data training, nilai ini masih menunjukkan kinerja yang cukup baik dalam mengenali kasus positif pada data testing.\n",
    "- **CV Recall Mean**: Nilai rata-rata recall dari 10-fold cross-validation adalah 0.704109. Ini menunjukkan bahwa secara keseluruhan, model mampu mengenali sekitar 70.41% dari total kasus positif pada data validasi silang. \n",
    "- **CV Recall Std**: Standar deviasi recall dari 10-fold cross-validation adalah 0.011219. Nilai ini menunjukkan variasi atau ketidakpastian dari hasil recall pada setiap fold dalam cross-validation. Standar deviasi yang kecil menunjukkan bahwa hasil model cukup konsisten di seluruh fold cross-validation.\n",
    "\n",
    "### Kesimpulan:\n",
    "Model Decision Tree yang digunakan menunjukkan performa yang sangat baik dalam mengenali kasus positif pada data training, tetapi ini mungkin disebabkan oleh overfitting. Recall pada data testing lebih rendah, menunjukkan bahwa model tidak mampu menggeneralisasi dengan baik pada data yang belum pernah dilihat sebelumnya. Meskipun demikian, performa model ini masih cukup baik dan konsisten di berbagai fold cross-validation. Untuk mengatasi overfitting, metode seperti pruning atau tuning hyperparameter dapat dipertimbangkan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ensamble Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning adalah teknik machine learning yang **menggabungkan prediksi dari beberapa model** untuk meningkatkan performa keseluruhan dari sistem. Model baru ini sering kali lebih robust dan lebih akurat. Ada dua jenis model ensemble learning yang kita gunakan:\n",
    "\n",
    "- **Bagging**: Bagging adalah singkatan dari Bootstrap Aggregating. Bagging mendapatkan namanya karena menggabungkan Bootstrapping dan Aggregation untuk membentuk satu model ensemble. `Random Forest` adalah contoh populer dari algoritma bagging.\n",
    "- **Boosting**: Dalam boosting, model dilatih secara berurutan, dengan setiap model berfokus pada memperbaiki kesalahan dari model sebelumnya. `AdaBoost` adalah salah satu algoritma boosting yang kita gunakan. Dalam kode kita, kita menggunakan `AdaBoostClassifier` untuk mengimplementasikan teknik boosting ini.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing pipelines\n",
    "num_pipeline = make_pipeline(MinMaxScaler())\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder()) \n",
    "\n",
    "# Define preprocessing column transformer\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, selected_num_cols),\n",
    "    ('cat', cat_pipeline, selected_cat_cols)\n",
    "])\n",
    "\n",
    "# Define model pipeline\n",
    "model_pipeline = make_pipeline(preprocessing_pipeline, RandomForestClassifier())\n",
    "\n",
    "#Model Training\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions for training and test sets\n",
    "y_train_pred = model_pipeline.predict(X_train)\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Generate classification reports for training and test sets\n",
    "print(f'Train Recall Score Before Tuning : \\n', recall_score(y_train, y_train_pred), '\\n')\n",
    "print(f'Test Recall Score Before Tuning: \\n', recall_score(y_test, y_test_pred), '\\n')\n",
    "\n",
    "# Cross Validation\n",
    "recall_train_cross_val = cross_val_score(model_pipeline,\n",
    "                                     X_train,\n",
    "                                     y_train,\n",
    "                                     cv=10,\n",
    "                                     scoring=\"recall\")\n",
    "\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "rf_results_df = pd.DataFrame({\n",
    "    'Metric': ['Train Recall', 'Test Recall', 'CV Recall Mean', 'CV Recall Std'],\n",
    "    'Value': [recall_score(y_train, y_train_pred), recall_score(y_test, y_test_pred), recall_train_cross_val.mean(), recall_train_cross_val.std()]\n",
    "})\n",
    "\n",
    "print(rf_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Evaluasi Model Random Forest\n",
    "\n",
    "#### Train Recall Score Before Tuning:\n",
    "- **Nilai**: 1.0\n",
    "- **Penjelasan**: Nilai recall pada data training menunjukkan bahwa model Random Forest mampu mengenali 100% dari total kasus positif di dalam data training. Ini menunjukkan bahwa model sangat baik dalam mendeteksi semua kasus positif pada data training, tetapi mungkin mengalami overfitting karena performa yang terlalu sempurna.\n",
    "\n",
    "#### Test Recall Score Before Tuning:\n",
    "- **Nilai**: 0.6581325301204819\n",
    "- **Penjelasan**: Nilai recall pada data testing menunjukkan bahwa model Random Forest mampu mengenali 65.81% dari total kasus positif di dalam data testing. Hasil ini menunjukkan penurunan kinerja dibandingkan dengan data training, yang mungkin mengindikasikan overfitting.\n",
    "\n",
    "#### Tabel Evaluasi Model:\n",
    "| Metric         | Value    |\n",
    "|----------------|----------|\n",
    "| Train Recall   | 1.000000 |\n",
    "| Test Recall    | 0.658133 |\n",
    "| CV Recall Mean | 0.651392 |\n",
    "| CV Recall Std  | 0.020068 |\n",
    "\n",
    "- **Train Recall**: Nilai ini menunjukkan bahwa model dapat mengenali 100% dari total kasus positif pada data training. Model ini menunjukkan tanda-tanda overfitting, di mana model terlalu cocok dengan data training.\n",
    "- **Test Recall**: Nilai ini menunjukkan bahwa model dapat mengenali sekitar 65.81% dari total kasus positif pada data testing. Meskipun lebih rendah dari nilai recall pada data training, nilai ini masih menunjukkan kinerja yang cukup baik dalam mengenali kasus positif pada data testing.\n",
    "- **CV Recall Mean**: Nilai rata-rata recall dari 10-fold cross-validation adalah 0.651392. Ini menunjukkan bahwa secara keseluruhan, model mampu mengenali sekitar 65.14% dari total kasus positif pada data validasi silang. \n",
    "- **CV Recall Std**: Standar deviasi recall dari 10-fold cross-validation adalah 0.020068. Nilai ini menunjukkan variasi atau ketidakpastian dari hasil recall pada setiap fold dalam cross-validation. Standar deviasi yang kecil menunjukkan bahwa hasil model cukup konsisten di seluruh fold cross-validation.\n",
    "\n",
    "### Kesimpulan:\n",
    "Model Random Forest yang digunakan menunjukkan performa yang sangat baik dalam mengenali kasus positif pada data training, tetapi ini mungkin disebabkan oleh overfitting. Recall pada data testing lebih rendah, menunjukkan bahwa model tidak mampu menggeneralisasi dengan baik pada data yang belum pernah dilihat sebelumnya. Meskipun demikian, performa model ini masih cukup baik dan konsisten di berbagai fold cross-validation. Untuk mengatasi overfitting, metode seperti pruning atau tuning hyperparameter dapat dipertimbangkan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **AdaBoostClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing pipelines\n",
    "num_pipeline = make_pipeline(MinMaxScaler())\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder())\n",
    "\n",
    "# Define preprocessing column transformer\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, selected_num_cols),\n",
    "    ('cat', cat_pipeline, selected_cat_cols)\n",
    "])\n",
    "\n",
    "# Define model pipeline\n",
    "model_pipeline = make_pipeline(preprocessing_pipeline, AdaBoostClassifier())\n",
    "\n",
    "# Model Training\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions for training and test sets\n",
    "y_train_pred = model_pipeline.predict(X_train)\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Generate classification reports for training and test sets\n",
    "print(f'Train Recall Score Before Tuning : \\n', recall_score(y_train, y_train_pred), '\\n')\n",
    "print(f'Test Recall Score Before Tuning: \\n', recall_score(y_test, y_test_pred), '\\n')\n",
    "\n",
    "# Cross Validation\n",
    "recall_train_cross_val = cross_val_score(model_pipeline,\n",
    "                                         X_train,\n",
    "                                         y_train,\n",
    "                                         cv=10,\n",
    "                                         scoring=\"recall\")\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "ada_results_df = pd.DataFrame({\n",
    "    'Metric': ['Train Recall', 'Test Recall', 'CV Recall Mean', 'CV Recall Std'],\n",
    "    'Value': [recall_score(y_train, y_train_pred), recall_score(y_test, y_test_pred), recall_train_cross_val.mean(), recall_train_cross_val.std()]\n",
    "})\n",
    "\n",
    "print(ada_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Evaluasi Model AdaBoostClassifier\n",
    "\n",
    "#### Train Recall Score Before Tuning:\n",
    "- **Nilai**: 0.6126074498567335\n",
    "- **Penjelasan**: Nilai recall pada data training menunjukkan bahwa model AdaBoostClassifier mampu mengenali 61.26% dari total kasus positif di dalam data training. Ini menunjukkan bahwa model cukup baik dalam mendeteksi kasus positif pada data training.\n",
    "\n",
    "#### Test Recall Score Before Tuning:\n",
    "- **Nilai**: 0.6204819277108434\n",
    "- **Penjelasan**: Nilai recall pada data testing menunjukkan bahwa model AdaBoostClassifier mampu mengenali 62.05% dari total kasus positif di dalam data testing. Hasil ini lebih tinggi sedikit dibandingkan dengan recall pada data training, yang menunjukkan bahwa model tidak mengalami overfitting dan mampu menggeneralisasi dengan baik.\n",
    "\n",
    "#### Tabel Evaluasi Model:\n",
    "| Metric         | Value    |\n",
    "|----------------|----------|\n",
    "| Train Recall   | 0.612607 |\n",
    "| Test Recall    | 0.620482 |\n",
    "| CV Recall Mean | 0.590277 |\n",
    "| CV Recall Std  | 0.028995 |\n",
    "\n",
    "- **Train Recall**: Nilai ini menunjukkan bahwa model dapat mengenali sekitar 61.26% dari total kasus positif pada data training. Model menunjukkan kinerja yang cukup baik dalam mengenali kasus positif pada data training.\n",
    "- **Test Recall**: Nilai ini menunjukkan bahwa model dapat mengenali sekitar 62.05% dari total kasus positif pada data testing. Nilai ini sedikit lebih tinggi dari nilai recall pada data training, menunjukkan bahwa model mampu menggeneralisasi dengan baik.\n",
    "- **CV Recall Mean**: Nilai rata-rata recall dari 10-fold cross-validation adalah 0.590277. Ini menunjukkan bahwa secara keseluruhan, model mampu mengenali sekitar 59.03% dari total kasus positif pada data validasi silang. \n",
    "- **CV Recall Std**: Standar deviasi recall dari 10-fold cross-validation adalah 0.028995. Nilai ini menunjukkan variasi atau ketidakpastian dari hasil recall pada setiap fold dalam cross-validation. Standar deviasi yang kecil menunjukkan bahwa hasil model cukup konsisten di seluruh fold cross-validation.\n",
    "\n",
    "### Kesimpulan:\n",
    "Model AdaBoostClassifier yang digunakan menunjukkan performa yang cukup baik dalam mengenali kasus positif pada data training dan testing. Model ini tidak mengalami overfitting, dengan nilai recall yang konsisten antara data training dan testing. Meskipun performanya sedikit lebih rendah dibandingkan Random Forest, model ini menunjukkan kemampuan generalisasi yang lebih baik dan konsistensi hasil yang baik di berbagai fold cross-validation. Untuk meningkatkan performa lebih lanjut, tuning hyperparameter dapat dilakukan atau metode ensemble lainnya dapat dipertimbangkan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pipeline Summary**\n",
    "\n",
    "| Model            | Recall Train | Recall Test | Difference | CV Mean |\n",
    "|------------------|--------------|-------------|------------|---------|\n",
    "| SVM              | 0.44         | 0.44        | 0.00       | 0.44    |\n",
    "| KNN              | 0.78         | 0.68        | 0.10       | 0.66    |\n",
    "| Decision Tree    | 1.00         | 0.71        | 0.29       | 0.70    |\n",
    "| Random Forest    | 1.00         | 0.66        | 0.34       | 0.65    |\n",
    "| AdaBoost         | 0.61         | 0.62        | 0.01       | 0.59    |\n",
    "\n",
    "Penjelasan:\n",
    "- **Recall Train**: Recall score pada data training.\n",
    "- **Recall Test**: Recall score pada data testing.\n",
    "- **Difference**: Selisih antara recall train dan recall test untuk mengidentifikasi overfitting.\n",
    "- **CV Mean**: Rata-rata recall score dari cross-validation (10-fold).\n",
    "\n",
    "Hasil ini menunjukkan bahwa model Decision Tree dan Random Forest mengalami overfitting dengan perbedaan besar antara recall train dan test. Model KNN dan AdaBoost menunjukkan performa yang lebih seimbang antara train dan test, dengan AdaBoost memiliki perbedaan yang paling kecil, menunjukkan generalisasi yang baik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters** yang dipilih untuk classifier K-Nearest Neighbors (KNN) adalah:\n",
    "\n",
    "1. **n_neighbors**: Jumlah tetangga terdekat yang dipertimbangkan saat membuat prediksi. Rentang nilai dari 1 hingga 10 dieksplorasi, yang merupakan rentang yang wajar untuk banyak dataset.\n",
    "2. **weights**: Fungsi bobot yang digunakan untuk memberikan bobot pada tetangga. Dua opsi yang dieksplorasi adalah: uniform (semua tetangga memiliki bobot yang sama) dan distance (tetangga diberi bobot berdasarkan jaraknya ke titik query).\n",
    "3. **algorithm**: Algoritma yang digunakan untuk menghitung tetangga terdekat. Empat opsi yang dieksplorasi adalah: auto (memilih algoritma terbaik berdasarkan dataset), ball_tree, kd_tree, dan brute (algoritma brute-force sederhana).\n",
    "\n",
    "**Grid Search** adalah metode tuning hyperparameter yang secara ekstensif mencari melalui grid kombinasi hyperparameter yang mungkin untuk menemukan yang terbaik. Grid Search memastikan bahwa semua kombinasi hyperparameter dieksplorasi, yang dapat menghasilkan performa yang lebih baik dibandingkan dengan pencarian acak atau metode lainnya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing pipelines\n",
    "num_pipeline = make_pipeline(MinMaxScaler())\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder()) \n",
    "\n",
    "# Define preprocessing column transformer\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, selected_num_cols),\n",
    "    ('cat', cat_pipeline, selected_cat_cols)\n",
    "])\n",
    "\n",
    "# Define model pipeline\n",
    "model_pipeline = make_pipeline(preprocessing_pipeline, KNeighborsClassifier())\n",
    "\n",
    "#Model Training\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions for training and test sets\n",
    "y_train_pred = model_pipeline.predict(X_train)\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Cross Validation\n",
    "recall_train_cross_val = cross_val_score(model_pipeline,\n",
    "                                     X_train,\n",
    "                                     y_train,\n",
    "                                     cv=10,\n",
    "                                     scoring=\"recall\")\n",
    "\n",
    "\n",
    "# Define Hyperparameters\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': list(range(1, 11)),\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'kneighborsclassifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model_pipeline, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=10, \n",
    "                           scoring='recall')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(grid_search.best_params_, '\\n')\n",
    "\n",
    "# Evaluate the best model\n",
    "KNN_best_model = grid_search.best_estimator_\n",
    "\n",
    "# Check Performance Model against Train-set\n",
    "y_pred_train = KNN_best_model.predict(X_train)\n",
    "y_pred_test = KNN_best_model.predict(X_test)\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "knn_results_tunning_df = pd.DataFrame({\n",
    "    'Metric': ['Train Recall Before Tuning', 'Test Recall Before Tuning', 'CV Recall Mean', 'CV Recall Std', 'Train Recall After Tuning', 'Test Recall After Tuning'],\n",
    "    'Value': [recall_score(y_train, y_train_pred), recall_score(y_test, y_test_pred), recall_train_cross_val.mean(), recall_train_cross_val.std(), recall_score(y_train, y_pred_train), recall_score(y_test, y_pred_test)]\n",
    "})\n",
    "\n",
    "display(knn_results_tunning_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Evaluasi Model KNN Setelah Hyperparameter Tuning\n",
    "\n",
    "1. **Train Recall Before Tuning**: \n",
    "   - **Nilai**: 0.775931\n",
    "   - **Penjelasan**: Model KNN mampu mengenali 77.59% dari total kasus positif pada data training sebelum tuning dilakukan.\n",
    "\n",
    "2. **Test Recall Before Tuning**: \n",
    "   - **Nilai**: 0.677711\n",
    "   - **Penjelasan**: Model KNN mampu mengenali 67.77% dari total kasus positif pada data testing sebelum tuning dilakukan.\n",
    "\n",
    "3. **CV Recall Mean**: \n",
    "   - **Nilai**: 0.661133\n",
    "   - **Penjelasan**: Rata-rata recall dari 10-fold cross-validation adalah 66.11% sebelum tuning dilakukan.\n",
    "\n",
    "4. **CV Recall Std**: \n",
    "   - **Nilai**: 0.019071\n",
    "   - **Penjelasan**: Standar deviasi recall dari 10-fold cross-validation adalah 0.019, menunjukkan variasi hasil yang kecil di berbagai fold.\n",
    "\n",
    "5. **Train Recall After Tuning**: \n",
    "   - **Nilai**: 1.000000\n",
    "   - **Penjelasan**: Setelah tuning, model KNN mampu mengenali 100% dari total kasus positif pada data training, yang menunjukkan adanya overfitting.\n",
    "\n",
    "6. **Test Recall After Tuning**: \n",
    "   - **Nilai**: 0.687500\n",
    "   - **Penjelasan**: Setelah tuning, model KNN mampu mengenali 68.75% dari total kasus positif pada data testing. Ini menunjukkan sedikit peningkatan dibandingkan sebelum tuning.\n",
    "\n",
    "### Kesimpulan:\n",
    "Setelah tuning hyperparameter, model KNN menunjukkan peningkatan kecil dalam recall pada data testing, tetapi recall pada data training meningkat secara signifikan, menunjukkan kemungkinan overfitting. Performa keseluruhan model masih cukup baik dengan peningkatan recall pada data testing dari 67.77% menjadi 68.75%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model pipeline\n",
    "joblib.dump(KNN_best_model, 'best_model_pipeline.joblib')\n",
    "\n",
    "# Save the preprocessing pipeline separately\n",
    "joblib.dump(preprocessing_pipeline, 'preprocessing_pipeline.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simpan pipeline model terbaik menggunakan joblib, yang dapat dimuat kembali nanti untuk melakukan inferensi model. Ini mencakup baik langkah-langkah preprocessing maupun classifier.\n",
    "- Simpan pipeline preprocessing secara terpisah menggunakan joblib, yang dapat digunakan kembali untuk preprocessing data di masa depan tanpa perlu melatih ulang seluruh pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengambilan Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Distribusi Customer Care Calls**:\n",
    "   - Data menunjukkan bahwa jumlah panggilan ke customer care bervariasi antara 2 hingga 7 panggilan.\n",
    "   - Sebagian besar pelanggan melakukan antara 2 hingga 5 panggilan ke customer care.\n",
    "   - Insight: Jumlah panggilan ke customer care bisa menjadi indikator kepuasan pelanggan dan dapat mempengaruhi apakah pengiriman tepat waktu atau tidak.\n",
    "\n",
    "2. **Biaya Produk (Cost of the Product)**:\n",
    "   - Biaya produk dalam dataset bervariasi antara 96 hingga 310.\n",
    "   - Mayoritas produk memiliki biaya dalam rentang menengah, dengan beberapa produk memiliki biaya yang sangat rendah atau sangat tinggi.\n",
    "   - Insight: Biaya produk mungkin mempengaruhi prioritas pengiriman dan dapat menjadi faktor dalam prediksi ketepatan waktu pengiriman.\n",
    "\n",
    "3. **Pembelian Sebelumnya (Prior Purchases)**:\n",
    "   - Jumlah pembelian sebelumnya berkisar antara 2 hingga 5.\n",
    "   - Sebagian besar pelanggan melakukan antara 2 hingga 4 pembelian sebelumnya.\n",
    "   - Insight: Pelanggan dengan lebih banyak pembelian sebelumnya mungkin memiliki hubungan yang lebih baik dengan perusahaan, yang bisa mempengaruhi ketepatan waktu pengiriman.\n",
    "\n",
    "4. **Diskon yang Diberikan (Discount Offered)**:\n",
    "   - Diskon yang diberikan bervariasi antara 1% hingga 19%.\n",
    "   - Sebagian besar diskon yang diberikan berada dalam rentang rendah hingga menengah.\n",
    "   - Insight: Diskon yang lebih tinggi mungkin diberikan untuk produk yang membutuhkan pengiriman lebih cepat, yang bisa mempengaruhi ketepatan waktu pengiriman.\n",
    "\n",
    "5. **Berat Produk (Weight in gms)**:\n",
    "   - Berat produk dalam dataset bervariasi antara 1492 gram hingga 5017 gram.\n",
    "   - Sebagian besar produk memiliki berat dalam rentang menengah, dengan beberapa produk sangat ringan atau sangat berat.\n",
    "   - Insight: Berat produk dapat mempengaruhi logistik pengiriman dan kemungkinan ketepatan waktu pengiriman.\n",
    "\n",
    "6. **Pentingnya Produk (Product Importance)**:\n",
    "   - Produk dikategorikan sebagai low, medium, dan high importance.\n",
    "   - Sebagian besar produk dikategorikan sebagai low dan medium importance, dengan sedikit produk yang dikategorikan sebagai high importance.\n",
    "   - Insight: Produk dengan tingkat kepentingan yang lebih tinggi mungkin diprioritaskan untuk pengiriman tepat waktu.\n",
    "\n",
    "### Insight Bisnis:\n",
    "- **Optimalisasi Layanan Pelanggan**: Mengurangi jumlah panggilan ke customer care dapat meningkatkan kepuasan pelanggan dan meningkatkan ketepatan waktu pengiriman.\n",
    "- **Strategi Harga dan Prioritas Pengiriman**: Produk dengan biaya menengah mendominasi, dan strategi penetapan harga yang tepat dapat membantu meningkatkan penjualan serta prioritas pengiriman.\n",
    "- **Program Diskon dan Pengiriman Cepat**: Memberikan diskon yang lebih tinggi pada produk tertentu dapat meningkatkan penjualan dan memastikan pengiriman tepat waktu.\n",
    "- **Pengelolaan Stok dan Logistik**: Fokus pada produk dengan berat menengah untuk mengoptimalkan logistik dan penyimpanan guna memastikan pengiriman tepat waktu.\n",
    "- **Peningkatan Nilai Produk**: Meningkatkan nilai tambah pada produk dengan tingkat kepentingan rendah dan menengah dapat meningkatkan penjualan dan memastikan pengiriman tepat waktu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kesimpulan**\n",
    "\n",
    "| Model            | Recall Train | Recall Test | Difference | CV Mean |\n",
    "|------------------|--------------|-------------|------------|---------|\n",
    "| SVM              | 0.44         | 0.44        | 0.00       | 0.44    |\n",
    "| KNN              | 0.78         | 0.68        | 0.10       | 0.66    |\n",
    "| Decision Tree    | 1.00         | 0.71        | 0.29       | 0.70    |\n",
    "| Random Forest    | 1.00         | 0.66        | 0.34       | 0.65    |\n",
    "| AdaBoost         | 0.61         | 0.62        | 0.01       | 0.59    |\n",
    "\n",
    "Berdasarkan skor recall test dan CV Mean yang disajikan dalam tabel, **model KNN adalah pilihan terbaik untuk klasifikasi**, diikuti oleh model Decision Tree. Selain itu, tuning hyperparameter, rekayasa fitur, dan metode ensemble dapat digunakan untuk lebih meningkatkan performa model-model ini.\n",
    "\n",
    "Setelah menggunakan Grid Search, hyperparameter terbaik yang ditemukan untuk Model KNN adalah:\n",
    "* 'kneighborsclassifier__algorithm': 'auto'\n",
    "* 'kneighborsclassifier__n_neighbors': 9\n",
    "* 'kneighborsclassifier__weights': 'distance'\n",
    "\n",
    "Setelah menggunakan `KNN best model`, model mencapai recall train sebesar 1.00 dan recall test sebesar 0.687 setelah tuning hyperparameter. Sebelum tuning, recall train adalah 0.78 dan recall test adalah 0.68. Rata-rata recall cross-validation adalah 0.66 dengan standar deviasi 0.019.\n",
    "\n",
    "Kesimpulannya, tuning hyperparameter **meningkatkan skor recall** pada data testing dan **model ini tampil sangat baik** untuk klasifikasi, meskipun terdapat sedikit indikasi overfitting pada data training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rekomendasi** :\n",
    "\n",
    "Berdasarkan hasil yang telah diperoleh, berikut adalah beberapa rekomendasi untuk model klasifikasi KNN:\n",
    "\n",
    "1. **Mengurangi Overfitting**: Recall train sebesar 1.00 dan recall test sebesar 0.687 setelah tuning hyperparameter menunjukkan bahwa model mungkin mengalami overfitting terhadap data training. Untuk mengurangi overfitting, kita dapat mengurangi jumlah tetangga terdekat (`n_neighbors`), atau mencoba teknik validasi silang yang lebih kuat untuk memastikan model tidak terlalu cocok dengan data training.\n",
    "\n",
    "2. **Seleksi Fitur**: Dalam model ini, kita menggunakan MinMaxScaler untuk skala fitur numerik dan OrdinalEncoder untuk fitur kategorikal. Di model selanjutnya, kita dapat mencoba StandardScaler untuk scaling dan OneHotEncoder untuk encoding data kategorikal. Selain itu, kita dapat menggunakan PCA (Principal Component Analysis) untuk mengurangi dimensi data dan meningkatkan performa model.\n",
    "\n",
    "3. **Penanganan Data Tidak Seimbang**: Dalam model ini, kita belum secara eksplisit menangani data yang tidak seimbang. Di model selanjutnya, kita dapat mempertimbangkan teknik seperti oversampling (misalnya, menggunakan SMOTE) atau undersampling untuk menyeimbangkan data. Ini dapat membantu meningkatkan performa model dan mencegah bias terhadap kelas mayoritas.\n",
    "\n",
    "4. **Evaluasi Model**: Selain menggunakan recall, kita juga dapat mengevaluasi model dengan metrik lain seperti akurasi, presisi, dan F1 score. Hal ini dapat memberikan evaluasi yang lebih komprehensif terhadap performa model dan mengidentifikasi kekuatan serta kelemahannya.\n",
    "\n",
    "5. **Eksplorasi Hyperparameter Lainnya**: Selain hyperparameter yang sudah diuji, kita bisa mengeksplorasi hyperparameter lain seperti `leaf_size`, `p` (parameter jarak), dan `metric` (metrik jarak) untuk lebih mengoptimalkan performa model KNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan hasil analisis data dan model KNN yang telah dibangun, berikut adalah beberapa rekomendasi bisnis yang dapat diambil untuk meningkatkan ketepatan waktu pengiriman dan efisiensi operasional:\n",
    "\n",
    "1. **Optimalisasi Layanan Pelanggan**:\n",
    "   - Data menunjukkan bahwa jumlah panggilan ke customer care bervariasi dan bisa menjadi indikator kepuasan pelanggan. Dengan meningkatkan efisiensi dan responsivitas layanan pelanggan, perusahaan dapat mengurangi jumlah panggilan berulang dan meningkatkan ketepatan waktu pengiriman.\n",
    "\n",
    "2. **Strategi Harga dan Prioritas Pengiriman**:\n",
    "   - Biaya produk yang berada dalam rentang menengah mendominasi data. Perusahaan dapat mempertimbangkan untuk menawarkan lebih banyak produk dalam rentang harga ini untuk meningkatkan penjualan dan memastikan prioritas pengiriman yang sesuai berdasarkan nilai produk.\n",
    "\n",
    "3. **Program Diskon yang Tepat Sasaran**:\n",
    "   - Diskon yang diberikan dapat mempengaruhi ketepatan waktu pengiriman. Memberikan diskon yang lebih tinggi pada produk tertentu dapat meningkatkan penjualan dan memastikan pengiriman lebih cepat untuk produk-produk yang diprioritaskan.\n",
    "\n",
    "4. **Pengelolaan Stok dan Logistik**:\n",
    "   - Berat produk yang bervariasi menunjukkan perlunya pengelolaan stok yang efisien. Fokus pada produk dengan berat menengah dapat membantu mengoptimalkan logistik dan penyimpanan, yang pada gilirannya dapat memastikan pengiriman tepat waktu.\n",
    "\n",
    "5. **Peningkatan Nilai Produk**:\n",
    "   - Produk dengan tingkat kepentingan rendah dan menengah mendominasi data. Perusahaan dapat meningkatkan nilai tambah pada produk-produk ini melalui peningkatan kualitas atau fitur untuk menarik lebih banyak pelanggan dan memastikan pengiriman yang lebih tepat waktu.\n",
    "\n",
    "6. **Analisis dan Penanganan Data Tidak Seimbang**:\n",
    "   - Dalam model ini, kita dapat mempertimbangkan teknik penanganan data tidak seimbang seperti oversampling atau undersampling untuk memastikan model tidak bias terhadap kelas mayoritas dan meningkatkan prediksi ketepatan waktu pengiriman.\n",
    "\n",
    "7. **Evaluasi dan Pemantauan Terus-Menerus**:\n",
    "   - Selain recall, perusahaan dapat menggunakan metrik lain seperti akurasi, presisi, dan F1 score untuk evaluasi model yang lebih komprehensif. Evaluasi dan pemantauan terus-menerus dapat membantu mengidentifikasi area perbaikan dan memastikan performa model tetap optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Apa itu Bagging dan Bagaimana Cara Kerjanya:**\n",
    "\n",
    "Bagging atau Bootstrap Aggregating adalah teknik dalam ensemble learning yang diperkenalkan oleh Leo Breiman pada tahun 1996. Tujuan dari bagging adalah untuk mengurangi variabilitas dan overfitting pada model machine learning.\n",
    "\n",
    "Cara kerja bagging melibatkan langkah-langkah berikut:\n",
    "\n",
    "- Membuat beberapa subset dari data pelatihan dengan metode resampling menggunakan penggantian (bootstrap sampling).\n",
    "- Setiap subset data ini digunakan untuk melatih model machine learning yang berbeda.\n",
    "- Hasil prediksi dari setiap model digabungkan menggunakan metode voting atau averaging.\n",
    "- Dengan menggunakan bagging, kita bisa mengurangi variabilitas dan overfitting pada model, sehingga model menjadi lebih stabil dan akurat.\n",
    "\n",
    "2. **Perbedaan Cara Kerja Algoritma Random Forest dan KNN:**\n",
    "\n",
    "Berikut adalah beberapa perbedaan utama antara Random Forest dan KNN:\n",
    "\n",
    "- **Pendekatan Model**: Random Forest adalah metode ensemble yang menggunakan beberapa pohon keputusan yang dilatih secara paralel. Sebaliknya, KNN (K-Nearest Neighbors) adalah algoritma lazy learning yang membuat prediksi berdasarkan kedekatan data dengan data pelatihan terdekat.\n",
    "- **Proses Pelatihan**: Random Forest melibatkan proses pelatihan yang kompleks di mana beberapa pohon keputusan dilatih menggunakan subset data pelatihan. Di sisi lain, KNN tidak memiliki fase pelatihan yang eksplisit dan hanya menyimpan data pelatihan untuk digunakan dalam prediksi.\n",
    "- **Proses Prediksi**: Random Forest membuat prediksi dengan menggabungkan hasil dari semua pohon keputusan menggunakan voting atau averaging. Sedangkan KNN membuat prediksi dengan mencari k tetangga terdekat dari data yang akan diprediksi dan menggunakan mayoritas label dari tetangga tersebut.\n",
    "- **Kinerja dan Penggunaan**: Random Forest lebih kompleks dan lebih cocok untuk menangani data besar. KNN lebih sederhana namun bisa menjadi lambat dan kurang efisien dengan dataset yang sangat besar karena harus menghitung jarak ke semua titik data pelatihan.\n",
    "\n",
    "3. **Apa itu Cross Validation?**\n",
    "\n",
    "Cross validation adalah teknik untuk mengevaluasi model machine learning dengan membagi data menjadi beberapa subset. Setiap subset akan bergantian digunakan sebagai data validasi sementara subset lainnya digunakan sebagai data pelatihan.\n",
    "\n",
    "Ada beberapa jenis cross validation, di antaranya:\n",
    "\n",
    "- **Holdout Validation**: Membagi data menjadi dua bagian, satu untuk pelatihan dan satu lagi untuk validasi.\n",
    "- **K-fold Cross Validation**: Membagi data menjadi k bagian. Setiap bagian digunakan sebagai data validasi secara bergantian sementara bagian lainnya digunakan untuk pelatihan.\n",
    "- **Leave-one-out Cross Validation**: Membagi data menjadi n bagian, di mana setiap bagian hanya berisi satu data. Setiap data tersebut digunakan sebagai validasi secara bergantian sementara data lainnya digunakan untuk pelatihan.\n",
    "\n",
    "Cross validation membantu mengurangi bias dan variansi pada model, serta meningkatkan stabilitas dan akurasi model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
